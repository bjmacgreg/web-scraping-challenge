{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import os\n",
    "import requests\n",
    "#executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "#browser = Browser('chrome', executable_path, headless=False)\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", usr/local/bin/chromedriver, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.NASA_Mars_news_db\n",
    "collection = db.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = bs(response.text, 'lxml')\n",
    "print(soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info\n",
    "# results are returned as an iterable list\n",
    "\n",
    "\n",
    "results = soup.find_all('div')\n",
    "#for result in results: \n",
    "#    print (str(result.get_text()))\n",
    "#results = soup.find_all()\n",
    "results\n",
    "\n",
    "#This way doesn't yield all the 'NoneType' errors, but will things come out in order?\n",
    "#news_title = soup.find_all('div', class_=\"content_title\")\n",
    "#news_p = soup.find_all('div', class_=\"rollover_description_inner\")\n",
    "#news_title\n",
    "#news_p\n",
    "\n",
    "\n",
    "\n",
    "#results = soup.find_all(class_=\"image_and_description_container\") - doesn't include title\n",
    "#results = soup.find_all('a', class_=\"image_and_description_container\")- nothing\n",
    "#results = soup.find_all('div', class_=\"image_and_description_container\") - title only shows up as html tag\n",
    "#results = soup.find_all('a', \"news\")- nothing\n",
    "#results = soup.find_all('a', \"/news\")- nothing\n",
    "#results = soup.find_all('a', href=\"/news\") - nope\n",
    "#results = soup.find_all('a', href=True).get_text() - illegal\n",
    "#results = soup.find_all('a').get('href') - illegal\n",
    "#results = soup.find_all(href=True)\n",
    "#results = soup.find_all(href=True, link=False) - legal, but had no effect\n",
    "#results = soup.find_all('a', href=True, img alt=False) - illegal (img alone wasn't, but had no effect)\n",
    "#results = soup.find_all('a', href=True, news=True) - illegal\n",
    "#results = soup.find_all('a', news=True) - nothing\n",
    "#results = soup.find_all(news=True) - nothing\n",
    "#results = soup.find_all('news'=True) - illegal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through returned results\n",
    "\n",
    "#for result in results: \n",
    "#    print (str(result.get_text()))\n",
    "\n",
    "for result in results:\n",
    "    # Error handling\n",
    "    try:\n",
    "        news_title = result.find('div', class_=\"content_title\")\n",
    "        news_p = result.find('div', class_=\"rollover_description_inner\")\n",
    "#        news_title = str(result.find('div', class_=\"content_title\").get_text())\n",
    "#        news_p = str(result.find('div', class_=\"rollover_description_inner\").get_text())\n",
    "        #news_title = str(result.find('div', class_=\"content_title\"))\n",
    "        #news_p = str(result.find('div', class_=\"rollover_description_inner\"))\n",
    "        #print(news_title)\n",
    "        #print(news_p)\n",
    "#        news_title = result.select('div', class_=\"content_title\").text\n",
    "#        news_p = result.select('div', class_=\"rollover_description_inner\").text\n",
    "        if (news_title and news_p):\n",
    "            print ('-------------')\n",
    "            print (str(news_title.get_text()))\n",
    "            print (str(news_p.get_text()))\n",
    "#            print(news_title)        \n",
    "#            print(news_p)\n",
    "\n",
    "#            print(news_title.text)        \n",
    "#print(news_p.text)\n",
    "            \n",
    "        # Dictionary to be inserted as a MongoDB document\n",
    "        if (news_title and news_p):\n",
    "            post = {\n",
    "                'news_title': str(news_title.get_text()),\n",
    "                'news_p': str(news_p.get_text())\n",
    "#                'news_title': news_title,\n",
    "#                'news_p': news_p           \n",
    "            \n",
    "            }\n",
    "            \n",
    "                #'news_title': news_title.text,\n",
    "                #'news_p': news_p.text\n",
    "                   #'url': link\n",
    "            collection.insert_one(post)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "####How to get rid of Nones and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NASA_news = db.items.find()\n",
    "\n",
    "for article in NASA_news:\n",
    "    #print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = \"//img[@class='thumb']\"\n",
    "thumbnails = browser.find_by_xpath(xpath)\n",
    "#print(results[0])\n",
    "img = thumbnails[0]\n",
    "img.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = \"//a[@class='open-toggle']\"\n",
    "switch = browser.find_by_xpath(xpath)\n",
    "#print(results[0])\n",
    "#img = thumbnails[0]\n",
    "switch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = soup.find('div', class_='img')\n",
    "#thumbnail = soup.find('div', class_='thumb')\n",
    "thumbnail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "#start at url, <ul class articles, first <img, src = ...\n",
    "<ul class=\"articles\">\n",
    "\t<li class=\"slide\">\n",
    "\t\t  <a class=\"fancybox\" data-description=\"NASAs Curiosity Mars rover spotted this dust devil with one of its Navigation Cameras around 11:35 a.m. local Mars time on Aug. 9, 2020 (the 2,847th Martian day, or sol, of the mission).\" data-fancybox-group=\"images\" data-fancybox-href=\"/spaceimages/images/largesize/PIA24039_hires.jpg\" data-link=\"/spaceimages/details.php?id=PIA24039\" data-thumbnail=\"/spaceimages/images/wallpaper/PIA24039-640x350.jpg\" data-title=\"Curiosity Spots a Dust Devil in the Hills\">\n",
    "\t\t\t<div class=\"image_and_description_container\">\n",
    "\t\t\t\t  <div class=\"rollover_description\">\n",
    "\t\t\t\t    <h3 class=\"release_date\">September 1, 2020</h3>\n",
    "\t\t\t\t\t<div class=\"item_tease_overlay\">Curiosity Spots a Dust Devil in the Hills</div>\n",
    "\t\t\t\t\t<div class=\"overlay_arrow\">\n",
    "\t\t\t\t\t  <img alt=\"more arrow\" src=\"/assets/images/overlay-arrow.png\">\n",
    "\t\t\t\t\t</div>\n",
    "\t\t\t\t  </div>\n",
    "\t\t\t\t  <div class=\"img\">\n",
    "\t\t\t\t\t<img alt=\"Curiosity Spots a Dust Devil in the Hills\" \n",
    "                    title=\"Curiosity Spots a Dust Devil in the Hills\" \n",
    "                    class=\"thumb\" \n",
    "                    src=\"/spaceimages/images/wallpaper/PIA24039-640x350.jpg\">\n",
    "\t\t\t\t  </div>\n",
    "\t\t\t\t  <div class=\"list_text_content\">\n",
    "\t\t\t\t    <div class=\"article_teaser_body\">September 1, 2020</div>\n",
    "\t\t\t\t<div class=\"content_title\">\n",
    "\t\t\t\t  Curiosity Spots a Dust Devil in the Hills\n",
    "\t\t\t\t</div>\n",
    "\t\t\t\t<div class=\"article_teaser_body\">\n",
    "\t\t\t\t  NASAs Curiosity Mars rover spotted this dust devil with one of its Navigation Cameras around 11:35 a.m. local Mars time on Aug. 9, 2020 (the 2,847th Martian day, or sol, of the mission).\n",
    "\t\t\t\t</div>\n",
    "\t\t\t  </div>\n",
    "\t\t</div>\n",
    "\t  </a>\n",
    "\n",
    "#then click on \"more info\" button\n",
    "\n",
    "\n",
    "#photo: <figure class='lede', <img class=main image, src = \n",
    "\n",
    "\n",
    "\n",
    "#maybe don't need to click - have download link for full-res link ,p.Full-Res JPG\n",
    "<section class=\"content_page module\">\n",
    "\t\t<div class=\"grid_layout\">\n",
    "\t\t  <article>\n",
    "\t\t\t<header id=\"page_header\">\n",
    "\t\t\t  <h2 class=\"category_title\">\n",
    "\t\t\t\t<a href=\"./\">Images</a>\n",
    "\t\t\t\t<span class=\"release_date\">| September 1, 2020</span>\n",
    "\t\t\t  </h2>\n",
    "\t\t\t  <h1 class=\"article_title\">\n",
    "\t\t\t\tCuriosity Spots a Dust Devil in the Hills\t\t\t  </h1>\n",
    "\t\t\t</header>\n",
    "\t\t\t<figure class=\"lede\">\n",
    "\t\t\t  <a href=\"/spaceimages/images/largesize/PIA24039_hires.jpg\">\n",
    "                <img alt=\"NASAs Curiosity Mars rover spotted this dust devil with one of its Navigation Cameras around 11:35 a.m. local Mars time on Aug. 9, 2020 (the 2,847th Martian day, or sol, of the mission).\" \n",
    "                title=\"NASAs Curiosity Mars rover spotted this dust devil with one of its Navigation Cameras around 11:35 a.m. local Mars time on Aug. 9, 2020 (the 2,847th Martian day, or sol, of the mission).\" \n",
    "                class=\"main_image\" \n",
    "                src=\"/spaceimages/images/largesize/PIA24039_hires.jpg\"></a>\n",
    "\t\t\t</figure>\n",
    "\t\t\t<div class=\"clearfix\" id=\"primary_column\">\n",
    "\t\t\t  <div class=\"wysiwyg_content\">\n",
    "\t\t\t\t<p><a href=\"https://photojournal.jpl.nasa.gov/archive/PIA24039.gif\" target=\"new\"><b>Click here for animation</b></a></p><p>NASA's Curiosity Mars rover spotted this dust devil with one of its Navigation Cameras around 11:35 a.m. local Mars time on Aug. 9, 2020 (the 2,847th Martian day, or sol, of the mission). The frames in this GIF were shot over 4 minutes and 15 seconds.</p><p>Taken from the \"Mary Anning\" drill site, this dust devil appears to be passing through small hills just above Curiosity's present location on Mount Sharp. The dust devil is approximately one-third to a half-mile (half-a-kilometer to a kilometer) away and estimated to be about 16 feet (5 meters) wide. The dust plume disappears past the top of the frame, so an exact height can't be known, but it's estimated to be at least 164 feet (50 meters) tall.</p><p>Contrast has been modified to make frame-to-frame changes easier to see.</p><p>For more information about Curiosity, visit <a href=\"http://mars.jpl.nasa.gov/msl\" target=\"new\">http://mars.jpl.nasa.gov/msl</a> or <a href=\"https://www.nasa.gov/mission_pages/msl/index.html\" target=\"new\">https://www.nasa.gov/mission_pages/msl/index.html</a>.\t\t\t  </p></div>\n",
    "\t\t\t  <a href=\"index.php?category=\">View all Images</a>\n",
    "\t\t\t</div>\n",
    "\t\t\t<div id=\"secondary_column\">\n",
    "\t\t\t  <aside class=\"image_detail_module\">\n",
    "\t\t\t\t<h1 class=\"sidebar_title\">Image Details</h1>\n",
    "\t\t\t\t<ul>\n",
    "\t\t\t\t<li><div class=\"mission\"><p>Mission: <a href=\"index.php?search=Mars+Science+Laboratory+%28MSL%29\">Mars Science Laboratory (MSL)</a></p></div></li><li><div class=\"mission\"><p>Target: <a href=\"index.php?search=Mars\">Mars</a></p></div></li><li><div class=\"mission\"><p>Spacecraft: <a href=\"index.php?search=Curiosity\">Curiosity</a></p></div></li><li><div class=\"mission\"><p>Instrument: <a href=\"index.php?search=Navigation+Camera+%28MSL%29\">Navigation Camera (MSL)</a></p></div></li><li><div class=\"views\"><p>Views: 0</p></div></li><li>\n",
    "\t\t\t\t\t\t  <div class=\"download_tiff\">\n",
    "\t\t\t\t\t\t\t<p>Full-Res TIFF: <a href=\"//photojournal.jpl.nasa.gov/tiff/PIA24039.tif\">PIA24039.tif</a></p>\n",
    "\t\t\t\t\t\t  </div>\n",
    "\t\t\t\t\t\t</li><li>\n",
    "\t\t\t\t\t\t  <div class=\"download_tiff\">\n",
    "\t\t\t\t\t\t\t<p>Full-Res JPG: \n",
    "                                <a href=\"//photojournal.jpl.nasa.gov/jpeg/PIA24039.jpg\">PIA24039.jpg</a></p>\n",
    "\t\t\t\t\t\t  </div>\n",
    "\t\t\t\t\t\t</li><li>\n",
    "\t\t\t\t\t\t  <div class=\"credit\">\n",
    "\t\t\t\t\t\t\t<p>Image credit: NASA/JPL-Caltech/SSI</p>\n",
    "\t\t\t\t\t\t  </div>\n",
    "\t\t\t\t\t\t</li>\t\t\t\t</ul>\n",
    "\t\t\t  </aside>\n",
    "\t\t\t  <aside class=\"image_detail_module\">\n",
    "\t\t\t\t<h1 class=\"sidebar_title\">Wallpaper</h1>\n",
    "\t\t\t\tApplying Wallpaper:<br>\n",
    "\t\t\t\t1. Click on the screen resolution you would like to use.<br>\n",
    "\t\t\t\t2. Right-click on the image (control-click on a Mac) and select the option 'Set the Background' or 'Set as Wallpaper' (or similar).\n",
    "\t\t\t\t<br><br>\n",
    "\t\t\t\t<ul>\n",
    "\t\t\t\t<li>Fullscreen download sizes:</li><li><a href=\"images/wallpaper/PIA24039-800x600.jpg\" target=\"_blank\">800 x 600</a></li><li><a href=\"images/wallpaper/PIA24039-1024x768.jpg\" target=\"_blank\">1024 x 768</a></li><li><a href=\"images/wallpaper/PIA24039-1280x1024.jpg\" target=\"_blank\">1280 x 1024</a></li><li><a href=\"images/wallpaper/PIA24039-1600x1200.jpg\" target=\"_blank\">1600 x 1200</a></li><li><br>Widescreen download sizes:</li><li><a href=\"images/wallpaper/PIA24039-1280x800.jpg\" target=\"_blank\">1280 x 800</a></li><li><a href=\"images/wallpaper/PIA24039-1440x900.jpg\" target=\"_blank\">1440 x 900</a></li><li><a href=\"images/wallpaper/PIA24039-1920x1200.jpg\" target=\"_blank\">1920 x 1200</a><br>\t\t\t\t</li></ul>\n",
    "\t\t\t  </aside>\n",
    "\t\t\t</div>\n",
    "\t\t  </article>\n",
    "\t\t</div>\n",
    "\t  </section>\n",
    " \n",
    "    \n",
    "\n",
    "#click on top left Mars thumbnail <img src=\"/spaceimages/images/largesize/PIA24039_hires.jpg\" \n",
    "    #class=\"fancybox-image\" style=\"display: inline;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "* Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url)\n",
    "type(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_df = tables[0]\n",
    "\n",
    "mars_facts_df.set_index([0], inplace=True)\n",
    "\n",
    "mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_df.rename(columns=mars_facts_df.iloc[0]).drop(mars_facts_df.index[0])\n",
    "mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_html_table = mars_facts_df.to_html()\n",
    "mars_facts_html_table = mars_facts_html_table.replace('\\n', '')\n",
    "mars_facts_html_table\n",
    "print(mars_facts_html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mars's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save the url string for the full resolution hemisphere image as well as the Hemisphere title containing the hemisphere name. Use a Python dictionary to store these values using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = \"//img[@class='thumb']\"\n",
    "thumbnails = browser.find_by_xpath(xpath)\n",
    "#print(results[0])\n",
    "img = thumbnails[0]\n",
    "img.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = \"//a[@class='open-toggle']\"\n",
    "switch = browser.find_by_xpath(xpath)\n",
    "#print(results[0])\n",
    "#img = thumbnails[0]\n",
    "switch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'lxml')\n",
    "#img_url = soup.find(\"div\", class_=\"downloads\")\n",
    "#img_url = soup.findAll(\"div\", class_='downloads')\n",
    "#imgs = soup.find(\"div\", class_='downloads')\n",
    "#imgs = soup.find(\"div\", 'downloads', 'href')\n",
    "#imgs = soup.find(\"div\", 'downloads', 'href')\n",
    "#imgs = soup.find(\"div\", 'downloads', 'a')\n",
    "#imgs = soup.find(class_='downloads').get('li')\n",
    "#imgs = soup.find(\"a\").get('href')\n",
    "#imgs = soup.find(\"div\", 'downloads')\n",
    "#imgs = soup.find(\"div\", 'downloads')\n",
    "imgs = soup.find(class_='downloads')\n",
    "#imgs = soup.find(class_='downloads').get('href')\n",
    "#imgs = soup.find('downloads')\n",
    "#imgs = soup.find(class_='downloads').get('li')\n",
    "#imgs = soup.find(\"a\").get('href')\n",
    "imgs\n",
    "#for img in imgs:\n",
    "    #img_url = soup.find(\"a\").get('href')\n",
    "    #img_url = soup.get('href')\n",
    "    #img_url = soup.get('href')    \n",
    "#    print(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55610117/get-href-by-text-using-beautifulsoup\n",
    "\n",
    "html = browser.html\n",
    "soup = bs(html, 'lxml')\n",
    "\n",
    "#links = [link.text for link in soup.select('a:contains(Something3)')]\n",
    "\n",
    "links = [a['href'] for a in soup.select('a:contains(Original)')]\n",
    "\n",
    "#links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "#links = [a['href'] for a in soup.find_all('a', 'Original', href=True)]\n",
    "#links = [a['href'] for a in soup.find_all('a', Original, href=True)]\n",
    "links\n",
    "#good=[]\n",
    "#for link in links:\n",
    "#   if \"full.jpg\" == True:\n",
    "#    good.append([link])\n",
    "#print(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are not actually FULL resolution, but those are enormous tif downloads\n",
    "\n",
    "#https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\n",
    "#https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
    "#https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\n",
    "#https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hemisphere_image_urls = [\n",
    "#    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\"},\n",
    "#    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\"},\n",
    "#    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\"},\n",
    "#    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg\"},\n",
    "#]\n",
    "#07 - browser.links.find_by_partial_text('Next')\n",
    "#08 - browser.click_link_by_partial_text('next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - MongoDB and Flask Application\n",
    "\n",
    "Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "* Start by converting your Jupyter notebook into a Python script called `scrape_mars.py` with a function called `scrape` that will execute all of your scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "* Next, create a route called `/scrape` that will call your `scrape_mars.scrape` function. Note that you'll have to import `scrape_mars.py`. \n",
    "\n",
    "  * Store the dictionary that gets returned to your MongoDB.\n",
    "\n",
    "* Create an index route `/` that will query your Mongo database and pass the Mars data into an HTML template to be displayed. \n",
    "\n",
    "* Create a template HTML file called `index.html` that will take the dictionary of Mars data and display its values in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel free to create your own design.\n",
    "\n",
    "![final_app_part1.png](Images/final_app_part1.png)\n",
    "![final_app_part2.png](Images/final_app_part2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
